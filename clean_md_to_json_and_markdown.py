import json
import hashlib
from pathlib import Path
from collections import defaultdict


# üîπ –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å–∫—Ä–∏–ø—Ç–∞
SCRIPT_DIR = Path(__file__).parent

# üîπ –ü–æ–ª–Ω—ã–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
INPUT_MD = SCRIPT_DIR / "mikizol_by_category.md"
OUTPUT_JSON = SCRIPT_DIR / "mikizol_clean.json"
OUTPUT_MD = SCRIPT_DIR / "mikizol_clean.md"

# üî∏ –§—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –≤—ã—Ä–µ–∑–∞—Ç—å
stop_phrases = [
    "–û–û–û –ú–∏–∫–∏–∑–æ–ª", "¬©", "–í—Å–µ –ø—Ä–∞–≤–∞ –∑–∞—â–∏—â–µ–Ω—ã", "–ì–ª–∞–≤–Ω–∞—è", "–¢–µ–ª–µ—Ñ–æ–Ω", "–§–∞–∫—Å",
    "E-mail", "–û –∫–æ–º–ø–∞–Ω–∏–∏", "–ö–æ–Ω—Ç–∞–∫—Ç—ã", "–ù–æ–≤–æ—Å—Ç–∏", "–ü–æ–ª–∏—Ç–∏–∫–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏"
]

# üî∏ –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏
def remove_redundant_lines(text, stop_phrases):
    lines = text.split("\n")
    return "\n".join(
        line for line in lines
        if not any(phrase.lower() in line.lower() for phrase in stop_phrases)
    )

# üîπ –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ Markdown-—Ñ–∞–π–ª–∞
with open(INPUT_MD, "r", encoding="utf-8") as f:
    lines = f.readlines()

data = []
seen_hashes = set()
current_category = ""
current_url = ""
current_content = []

# üîπ –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥
for line in lines:
    stripped = line.strip()

    if not stripped:
        continue

    if stripped.startswith("# ") and not stripped.startswith("# http"):
        current_category = stripped[2:].strip()
        continue

    if stripped.startswith("# http"):
        if current_url and current_content:
            raw_text = "\n".join(current_content).strip()
            cleaned_text = remove_redundant_lines(raw_text, stop_phrases)
            text_hash = hashlib.md5(cleaned_text.encode("utf-8")).hexdigest()
            if text_hash not in seen_hashes:
                seen_hashes.add(text_hash)
                data.append({
                    "category": current_category,
                    "url": current_url,
                    "content": cleaned_text
                })
            current_content = []
        current_url = stripped[2:].strip()
        continue

    current_content.append(stripped)

# üî∏ –ü–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫
if current_url and current_content:
    raw_text = "\n".join(current_content).strip()
    cleaned_text = remove_redundant_lines(raw_text, stop_phrases)
    text_hash = hashlib.md5(cleaned_text.encode("utf-8")).hexdigest()
    if text_hash not in seen_hashes:
        data.append({
            "category": current_category,
            "url": current_url,
            "content": cleaned_text
        })

# ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON (–¥–ª—è RAG)
with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

# ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º Markdown (–¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞)
with open(OUTPUT_MD, "w", encoding="utf-8") as f:
    grouped = defaultdict(list)
    for item in data:
        grouped[item["category"]].append(item)

    for category, items in grouped.items():
        f.write(f"# {category}\n\n")
        for item in items:
            f.write(f"# {item['url']}\n\n{item['content']}\n\n---\n\n")

print("‚úÖ –ì–æ—Ç–æ–≤–æ: mikizol_clean.json –∏ mikizol_clean.md")
